# Server
PORT=3000
NODE_ENV=development

# CORS - comma-separated list of allowed origins (use * for all origins in development)
# In production, set this to your Vercel frontend URL
ALLOWED_ORIGINS=http://localhost:5173,http://localhost:3000

# Supabase
SUPABASE_URL=your_supabase_url_here
SUPABASE_ANON_KEY=your_supabase_anon_key_here
SUPABASE_SERVICE_ROLE_KEY=your_supabase_service_role_key_here

# Redis (for job queue - only needed if ENABLE_WORKERS=true)
REDIS_URL=redis://localhost:6379
ENABLE_WORKERS=false

# RapidAPI Twitter Search (https://rapidapi.com/omarmhaimdat/api/twitter-api45)
RAPIDAPI_KEY=your_rapidapi_key_here
RAPIDAPI_HOST=twitter-api45.p.rapidapi.com

# Search Keywords (comma-separated)
SEARCH_KEYWORDS_PRIMARY=x402,#x402,x402 protocol,HTTP 402
SEARCH_KEYWORDS_SECONDARY=402 payment,crypto payments API,web monetization

# Search Configuration
SEARCH_MAX_PAGES=5
SEARCH_MAX_PAGES_PER_USER=3
SEARCH_DELAY_MS=2000
SEARCH_TYPE=Top

# AI Providers (at least one API key required)
# Priority order: Mistral -> Cerebras -> OpenRouter

# Mistral AI (https://console.mistral.ai/)
# Uses standard /v1/chat/completions endpoint (OpenAI-compatible)
MISTRAL_API_KEY=
MISTRAL_MODEL=mistral-small-latest

# Cerebras AI (https://cloud.cerebras.ai/)
# Uses standard /v1/chat/completions endpoint (OpenAI-compatible)
CEREBRAS_API_KEY=
CEREBRAS_MODELS=llama-3.3-70b,llama3.1-70b,llama3.1-8b

# OpenRouter AI (https://openrouter.ai/) - fallback provider
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_MODEL=xiaomi/mimo-v2-flash:free

# AI Provider Settings
AI_PROVIDER_PRIORITY=mistral,cerebras,openrouter
AI_HIGH_TRAFFIC_THRESHOLD_MS=120000
AI_COOLDOWN_MS=300000

# Categorization Thresholds
KOL_MIN_FOLLOWERS=1000
KOL_MIN_ENGAGEMENT_SCORE=50
KOL_MIN_X402_RELEVANCE=30
KOL_MIN_X402_TWEETS_30D=3
DEV_MIN_TECH_SCORE=50
USER_MIN_X402_RELEVANCE=20
